{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7a914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing import libraries for data analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89fb4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1400000 entries, 0 to 1399999\n",
      "Data columns (total 49 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   srcip             1400000 non-null  object \n",
      " 1   sport             1400000 non-null  object \n",
      " 2   dstip             1400000 non-null  object \n",
      " 3   dsport            1400000 non-null  object \n",
      " 4   proto             1400000 non-null  object \n",
      " 5   state             1400000 non-null  object \n",
      " 6   dur               1400000 non-null  float64\n",
      " 7   sbytes            1400000 non-null  int64  \n",
      " 8   dbytes            1400000 non-null  int64  \n",
      " 9   sttl              1400000 non-null  int64  \n",
      " 10  dttl              1400000 non-null  int64  \n",
      " 11  sloss             1400000 non-null  int64  \n",
      " 12  dloss             1400000 non-null  int64  \n",
      " 13  service           1400000 non-null  object \n",
      " 14  Sload             1400000 non-null  float64\n",
      " 15  Dload             1400000 non-null  float64\n",
      " 16  Spkts             1400000 non-null  int64  \n",
      " 17  Dpkts             1400000 non-null  int64  \n",
      " 18  swin              1400000 non-null  int64  \n",
      " 19  dwin              1400000 non-null  int64  \n",
      " 20  stcpb             1400000 non-null  int64  \n",
      " 21  dtcpb             1400000 non-null  int64  \n",
      " 22  smeansz           1400000 non-null  int64  \n",
      " 23  dmeansz           1400000 non-null  int64  \n",
      " 24  trans_depth       1400000 non-null  int64  \n",
      " 25  res_bdy_len       1400000 non-null  int64  \n",
      " 26  Sjit              1400000 non-null  float64\n",
      " 27  Djit              1400000 non-null  float64\n",
      " 28  Stime             1400000 non-null  int64  \n",
      " 29  Ltime             1400000 non-null  int64  \n",
      " 30  Sintpkt           1400000 non-null  float64\n",
      " 31  Dintpkt           1400000 non-null  float64\n",
      " 32  tcprtt            1400000 non-null  float64\n",
      " 33  synack            1400000 non-null  float64\n",
      " 34  ackdat            1400000 non-null  float64\n",
      " 35  is_sm_ips_ports   1400000 non-null  int64  \n",
      " 36  ct_state_ttl      1400000 non-null  int64  \n",
      " 37  ct_flw_http_mthd  1114744 non-null  float64\n",
      " 38  is_ftp_login      1092962 non-null  float64\n",
      " 39  ct_ftp_cmd        1400000 non-null  object \n",
      " 40  ct_srv_src        1400000 non-null  int64  \n",
      " 41  ct_srv_dst        1400000 non-null  int64  \n",
      " 42  ct_dst_ltm        1400000 non-null  int64  \n",
      " 43  ct_src_ltm        1400000 non-null  int64  \n",
      " 44  ct_src_dport_ltm  1400000 non-null  int64  \n",
      " 45  ct_dst_sport_ltm  1400000 non-null  int64  \n",
      " 46  ct_dst_src_ltm    1400000 non-null  int64  \n",
      " 47  attack_cat        74964 non-null    object \n",
      " 48  label             1400000 non-null  int64  \n",
      "dtypes: float64(12), int64(28), object(9)\n",
      "memory usage: 523.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Renaming columns for better readability\n",
    "columns = [\n",
    "    'srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur', 'sbytes', 'dbytes',\n",
    "    'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload', 'Spkts', 'Dpkts',\n",
    "    'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len',\n",
    "    'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack',\n",
    "    'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login',\n",
    "    'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm',\n",
    "    'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat', 'label'\n",
    "]\n",
    "\n",
    "# Importing the both datasets of UNSW-NB15\n",
    "# Dataset: UNSW-NB15\n",
    "df1= pd.read_csv('../Data/UNSW-NB15_1.csv',names=columns, skiprows=1, low_memory=False)\n",
    "df2= pd.read_csv('../Data/UNSW-NB15_2.csv',names=columns, skiprows=1, low_memory=False)\n",
    "\n",
    "# Concatenating the two datasets into a single DataFrame\n",
    "df= pd.concat([df1,df2], ignore_index=True)\n",
    "\n",
    "# Displaying basic information about the DataFrame\n",
    "df.info()\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "df.head()\n",
    "\n",
    "# Checking for missing values in the DataFrame\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "# List all the columns in the DataFrame\n",
    "df.columns.tolist()\n",
    "\n",
    "# Displaying the unique values in the 'label' column\n",
    "df['label'].value_counts()\n",
    "\n",
    "\n",
    "# Dropping unnecessary columns from the DataFrame which are not needed for macine learning\n",
    "df.drop(columns=['srcip', 'sport', 'dstip', 'dsport', 'attack_cat'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec7f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 592294\n",
      "Shape of dataset: (1400000, 44)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Columns with string values that need to be encoded\n",
    "cat_columns = ['proto', 'service', 'state']\n",
    "\n",
    "# Creating ecoder object\n",
    "label_encoders={}           \n",
    "              \n",
    "for col in cat_columns:\n",
    "    le=LabelEncoder()\n",
    "    df[col]=le.fit_transform(df[col])\n",
    "    label_encoders[col] = le # Storing the encoder for later use\n",
    "    \n",
    "# Confirming that all values are now numeric\n",
    "df.dtypes.value_counts()\n",
    "\n",
    "# Checking class balance\n",
    "df['label'].value_counts(normalize=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\", df.isnull().sum().sum())\n",
    "\n",
    "# Confirm dataset shape\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "197bcf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1120000, 43)\n",
      "Shape of X_test: (280000, 43)\n",
      "NaNs in X_train: 473472\n",
      "NaNs in X_test: 118822\n",
      "✅ NaNs in X_train after clean-up: 0\n",
      "✅ NaNs in X_test after clean-up: 0\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features and target variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X= df.drop(columns=['label'])\n",
    "y=df['label']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting 'ct_ftp_cmd' column to numeric, replacing spaces with NaN\n",
    "X_train['ct_ftp_cmd'] = pd.to_numeric(X_train['ct_ftp_cmd'].replace(' ', np.nan), errors='coerce')\n",
    "X_test['ct_ftp_cmd'] = pd.to_numeric(X_test['ct_ftp_cmd'].replace(' ', np.nan), errors='coerce')\n",
    "\n",
    "# Step 2: Fill NaNs with median \n",
    "X_train['ct_ftp_cmd'].fillna(X_train['ct_ftp_cmd'].median(), inplace=True)\n",
    "X_test['ct_ftp_cmd'].fillna(X_test['ct_ftp_cmd'].median(), inplace=True)\n",
    "\n",
    "\n",
    "# Displaying the shapes of the training and testing sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Checking for NaN values in the training and testing sets\n",
    "print(\"NaNs in X_train:\", np.isnan(X_train).sum().sum())\n",
    "print(\"NaNs in X_test:\", np.isnan(X_test).sum().sum())\n",
    "\n",
    "# Fill all missing values with the median of each column\n",
    "X_train = X_train.fillna(X_train.median(numeric_only=True))\n",
    "X_test = X_test.fillna(X_test.median(numeric_only=True))\n",
    "\n",
    "# Checking for NaN values again after filling\n",
    "print(\"✅ NaNs in X_train after clean-up:\", X_train.isnull().sum().sum())\n",
    "print(\"✅ NaNs in X_test after clean-up:\", X_test.isnull().sum().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd86ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[264542    366]\n",
      " [   408  14684]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    264908\n",
      "           1       0.98      0.97      0.97     15092\n",
      "\n",
      "    accuracy                           1.00    280000\n",
      "   macro avg       0.99      0.99      0.99    280000\n",
      "weighted avg       1.00      1.00      1.00    280000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model training and evaluation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Create the model with class_weights ='balanced' to handle any imbalance\n",
    "rf= RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Step 2: Training the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Making predictions on the test set\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "#Step 4: Evaluating the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
